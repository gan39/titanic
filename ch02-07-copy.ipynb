{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2.7 submitのその前に！　の写経","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\ngender_submission = pd.read_csv('../input/titanic/gender_submission.csv')\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlnoe'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlnoe'] = 1\n","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:33.409330Z","iopub.execute_input":"2023-01-02T06:46:33.409865Z","iopub.status.idle":"2023-01-02T06:46:33.522759Z","shell.execute_reply.started":"2023-01-02T06:46:33.409721Z","shell.execute_reply":"2023-01-02T06:46:33.521424Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:33.525012Z","iopub.execute_input":"2023-01-02T06:46:33.525392Z","iopub.status.idle":"2023-01-02T06:46:33.552741Z","shell.execute_reply.started":"2023-01-02T06:46:33.525360Z","shell.execute_reply":"2023-01-02T06:46:33.551557Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n3            4       1.0       1   \n4            5       0.0       3   \n\n                                                Name  Sex   Age  SibSp  Parch  \\\n0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n4                           Allen, Mr. William Henry    0  35.0      0      0   \n\n             Ticket     Fare Cabin  Embarked  FamilySize  IsAlnoe  \n0         A/5 21171   7.2500   NaN         0           2        0  \n1          PC 17599  71.2833   C85         1           2        0  \n2  STON/O2. 3101282   7.9250   NaN         0           1        1  \n3            113803  53.1000  C123         0           2        0  \n4            373450   8.0500   NaN         0           1        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>IsAlnoe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"delete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:33.554270Z","iopub.execute_input":"2023-01-02T06:46:33.554781Z","iopub.status.idle":"2023-01-02T06:46:33.567799Z","shell.execute_reply.started":"2023-01-02T06:46:33.554746Z","shell.execute_reply":"2023-01-02T06:46:33.566458Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:33.569536Z","iopub.execute_input":"2023-01-02T06:46:33.569925Z","iopub.status.idle":"2023-01-02T06:46:33.587448Z","shell.execute_reply.started":"2023-01-02T06:46:33.569893Z","shell.execute_reply":"2023-01-02T06:46:33.585824Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  FamilySize  IsAlnoe\n0       3    0  22.0      1      0   7.2500         0           2        0\n1       1    1  38.0      1      0  71.2833         1           2        0\n2       3    1  26.0      0      0   7.9250         0           1        1\n3       1    1  35.0      1      0  53.1000         0           2        0\n4       3    0  35.0      0      0   8.0500         0           1        1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>IsAlnoe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## ホールドアウト検証","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:33.590364Z","iopub.execute_input":"2023-01-02T06:46:33.591312Z","iopub.status.idle":"2023-01-02T06:46:34.219094Z","shell.execute_reply.started":"2023-01-02T06:46:33.591253Z","shell.execute_reply":"2023-01-02T06:46:34.217731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"categorical_features = ['Embarked', 'Pclass', 'Sex']","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:34.220664Z","iopub.execute_input":"2023-01-02T06:46:34.221182Z","iopub.status.idle":"2023-01-02T06:46:34.226620Z","shell.execute_reply.started":"2023-01-02T06:46:34.221130Z","shell.execute_reply":"2023-01-02T06:46:34.225438Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"params = {\n    'objective':'binary',\n    'max_bin':300,\n    'learning_rate':0.05,\n    'num_leaves':40\n}","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:34.228049Z","iopub.execute_input":"2023-01-02T06:46:34.228460Z","iopub.status.idle":"2023-01-02T06:46:34.239208Z","shell.execute_reply.started":"2023-01-02T06:46:34.228428Z","shell.execute_reply":"2023-01-02T06:46:34.237759Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\n\nlgb_train = lgb.Dataset(X_train, y_train,\n                       categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train,\n                      categorical_feature=categorical_features)\n\nmodel = lgb.train(params, lgb_train,\n                 valid_sets=[lgb_train, lgb_eval],\n                 verbose_eval=10,\n                 num_boost_round=1000,\n                 early_stopping_rounds=10)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:34.241243Z","iopub.execute_input":"2023-01-02T06:46:34.241626Z","iopub.status.idle":"2023-01-02T06:46:35.475974Z","shell.execute_reply.started":"2023-01-02T06:46:34.241590Z","shell.execute_reply":"2023-01-02T06:46:35.474956Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 239, number of negative: 384\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002822 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 205\n[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179\n[LightGBM] [Info] Start training from score -0.474179\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.505696\tvalid_1's binary_logloss: 0.532008\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.422967\tvalid_1's binary_logloss: 0.478904\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.373496\tvalid_1's binary_logloss: 0.448045\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.342723\tvalid_1's binary_logloss: 0.439465\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.318708\tvalid_1's binary_logloss: 0.438633\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.299108\tvalid_1's binary_logloss: 0.436609\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\ttraining's binary_logloss: 0.282689\tvalid_1's binary_logloss: 0.437435\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[61]\ttraining's binary_logloss: 0.2972\tvalid_1's binary_logloss: 0.435949\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n  _log_warning('Using categorical_feature in Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:35.480687Z","iopub.execute_input":"2023-01-02T06:46:35.483187Z","iopub.status.idle":"2023-01-02T06:46:35.491882Z","shell.execute_reply.started":"2023-01-02T06:46:35.483137Z","shell.execute_reply":"2023-01-02T06:46:35.490705Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([0.03935242, 0.52380086, 0.11487096, 0.07538967, 0.39761111,\n       0.41886672, 0.7023978 , 0.13190461, 0.74563405, 0.0485806 ])"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = (y_pred > 0.5).astype(int)\ny_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:35.495096Z","iopub.execute_input":"2023-01-02T06:46:35.495700Z","iopub.status.idle":"2023-01-02T06:46:35.505275Z","shell.execute_reply.started":"2023-01-02T06:46:35.495662Z","shell.execute_reply":"2023-01-02T06:46:35.504175Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0])"},"metadata":{}}]},{"cell_type":"code","source":"sub = pd.read_csv('../input/titanic/gender_submission.csv')\n\nsub['Survived'] = y_pred\nsub.to_csv('submission_lightgbm_holdout.csv', index=False)\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:35.507210Z","iopub.execute_input":"2023-01-02T06:46:35.507921Z","iopub.status.idle":"2023-01-02T06:46:35.531285Z","shell.execute_reply.started":"2023-01-02T06:46:35.507885Z","shell.execute_reply":"2023-01-02T06:46:35.529899Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 交差検証(Cross Validation)","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\ngender_submission = pd.read_csv('../input/titanic/gender_submission.csv')\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\ndelete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:35.532975Z","iopub.execute_input":"2023-01-02T06:46:35.534199Z","iopub.status.idle":"2023-01-02T06:46:35.583990Z","shell.execute_reply.started":"2023-01-02T06:46:35.534144Z","shell.execute_reply":"2023-01-02T06:46:35.582667Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  FamilySize  IsAlone\n0       3    0  22.0      1      0   7.2500         0           2        0\n1       1    1  38.0      1      0  71.2833         1           2        0\n2       3    1  26.0      0      0   7.9250         0           1        1\n3       1    1  35.0      1      0  53.1000         0           2        0\n4       3    0  35.0      0      0   8.0500         0           1        1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ny_preds = []\nmodels = []\n\n# trainのOut of fold(学習に使わなかったfold)\n# 各分割でのoofに対する予測値を格納する\noof_train = np.zeros((len(X_train),))\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\n\ncategorical_features = ['Embarked', 'Pclass', 'Sex']\n\nparams = {\n    'objective':'binary',\n    'max_bin':300,\n    'learning_rate':0.05,\n    'num_leaves':40\n}\n\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n    \n    lgb_train = lgb.Dataset(X_tr, y_tr,\n                          categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train,\n                          categorical_feature=categorical_features)\n    \n    model = lgb.train(params, lgb_train,\n                     valid_sets=[lgb_train, lgb_eval],\n                     verbose_eval=10,\n                     num_boost_round=1000,\n                     early_stopping_rounds=10)\n    \n    oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    \n    y_preds.append(y_pred)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:35.585337Z","iopub.execute_input":"2023-01-02T06:46:35.585710Z","iopub.status.idle":"2023-01-02T06:46:36.039094Z","shell.execute_reply.started":"2023-01-02T06:46:35.585670Z","shell.execute_reply":"2023-01-02T06:46:36.037672Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n  _log_warning('Using categorical_feature in Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 273, number of negative: 439\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000223 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 214\n[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n[LightGBM] [Info] Start training from score -0.475028\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.506339\tvalid_1's binary_logloss: 0.516151\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.426275\tvalid_1's binary_logloss: 0.446237\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.377059\tvalid_1's binary_logloss: 0.404444\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.346209\tvalid_1's binary_logloss: 0.386344\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.322399\tvalid_1's binary_logloss: 0.380195\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.299854\tvalid_1's binary_logloss: 0.374311\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\ttraining's binary_logloss: 0.282822\tvalid_1's binary_logloss: 0.37193\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\ttraining's binary_logloss: 0.267674\tvalid_1's binary_logloss: 0.369387\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[76]\ttraining's binary_logloss: 0.273353\tvalid_1's binary_logloss: 0.368793\n[LightGBM] [Info] Number of positive: 275, number of negative: 438\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 213\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385694 -> initscore=-0.465448\n[LightGBM] [Info] Start training from score -0.465448\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.503759\tvalid_1's binary_logloss: 0.534005\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.42069\tvalid_1's binary_logloss: 0.479807\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.366991\tvalid_1's binary_logloss: 0.450224\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.33524\tvalid_1's binary_logloss: 0.444745\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.313854\tvalid_1's binary_logloss: 0.441951\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.294242\tvalid_1's binary_logloss: 0.439825\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\ttraining's binary_logloss: 0.275352\tvalid_1's binary_logloss: 0.446902\nEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.294242\tvalid_1's binary_logloss: 0.439825\n[LightGBM] [Info] Number of positive: 284, number of negative: 429\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 216\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.398317 -> initscore=-0.412483\n[LightGBM] [Info] Start training from score -0.412483\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.506703\tvalid_1's binary_logloss: 0.507205\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.429763\tvalid_1's binary_logloss: 0.448299\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.379565\tvalid_1's binary_logloss: 0.407649\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.349661\tvalid_1's binary_logloss: 0.38774\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.329665\tvalid_1's binary_logloss: 0.376976\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.308788\tvalid_1's binary_logloss: 0.372537\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\ttraining's binary_logloss: 0.290603\tvalid_1's binary_logloss: 0.371338\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\ttraining's binary_logloss: 0.275381\tvalid_1's binary_logloss: 0.372815\nEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.290603\tvalid_1's binary_logloss: 0.371338\n[LightGBM] [Info] Number of positive: 275, number of negative: 438\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 212\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385694 -> initscore=-0.465448\n[LightGBM] [Info] Start training from score -0.465448\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.497251\tvalid_1's binary_logloss: 0.526756\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.415615\tvalid_1's binary_logloss: 0.470791\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.370439\tvalid_1's binary_logloss: 0.452221\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.337577\tvalid_1's binary_logloss: 0.438324\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.314554\tvalid_1's binary_logloss: 0.430896\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.297172\tvalid_1's binary_logloss: 0.433403\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[52]\ttraining's binary_logloss: 0.310614\tvalid_1's binary_logloss: 0.430446\n[LightGBM] [Info] Number of positive: 261, number of negative: 452\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 218\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.366059 -> initscore=-0.549162\n[LightGBM] [Info] Start training from score -0.549162\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.494281\tvalid_1's binary_logloss: 0.552251\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.41522\tvalid_1's binary_logloss: 0.487211\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.366058\tvalid_1's binary_logloss: 0.451263\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.334916\tvalid_1's binary_logloss: 0.43434\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.313536\tvalid_1's binary_logloss: 0.432532\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.315324\tvalid_1's binary_logloss: 0.432138\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(oof_train).to_csv('oof_train_kfold.csv', index=False)\n\nscores = [\n    m.best_score['valid_1']['binary_logloss'] for m in models\n]\n\nscore = sum(scores) / len(scores)\nprint('===CV Score===')\nprint(scores)\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T07:26:29.884038Z","iopub.execute_input":"2023-01-02T07:26:29.884527Z","iopub.status.idle":"2023-01-02T07:26:29.899326Z","shell.execute_reply.started":"2023-01-02T07:26:29.884490Z","shell.execute_reply":"2023-01-02T07:26:29.897802Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"===CV Score===\n[0.38009408187107163, 0.37924619589793584, 0.4050842067940025, 0.4450699329180633, 0.48255560255294955]\n0.41841000400680456\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n\ny_pred_oof = (oof_train > 0.5).astype(int)\naccuracy_score(y_train, y_pred_oof)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:36.062687Z","iopub.execute_input":"2023-01-02T06:46:36.063063Z","iopub.status.idle":"2023-01-02T06:46:36.082040Z","shell.execute_reply.started":"2023-01-02T06:46:36.063032Z","shell.execute_reply":"2023-01-02T06:46:36.080601Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.8294051627384961"},"metadata":{}}]},{"cell_type":"code","source":"len(y_preds)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:36.083794Z","iopub.execute_input":"2023-01-02T06:46:36.084604Z","iopub.status.idle":"2023-01-02T06:46:36.093470Z","shell.execute_reply.started":"2023-01-02T06:46:36.084552Z","shell.execute_reply":"2023-01-02T06:46:36.092172Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"y_preds[0][:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:36.095504Z","iopub.execute_input":"2023-01-02T06:46:36.096210Z","iopub.status.idle":"2023-01-02T06:46:36.107637Z","shell.execute_reply.started":"2023-01-02T06:46:36.096171Z","shell.execute_reply":"2023-01-02T06:46:36.106308Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([0.07903405, 0.3569554 , 0.04071679, 0.36745113, 0.41165963,\n       0.62777401, 0.6920704 , 0.16400441, 0.82285313, 0.02543809])"},"metadata":{}}]},{"cell_type":"code","source":"y_sub = sum(y_preds) / len(y_preds)\ny_sub = (y_sub > 0.5).astype(int)\ny_sub[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:36.109130Z","iopub.execute_input":"2023-01-02T06:46:36.110396Z","iopub.status.idle":"2023-01-02T06:46:36.122884Z","shell.execute_reply.started":"2023-01-02T06:46:36.110354Z","shell.execute_reply":"2023-01-02T06:46:36.121781Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"},"metadata":{}}]},{"cell_type":"code","source":"sub['Survived'] = y_sub\nsub.to_csv('submission_lightgbm_kfold.csv', index=False)\nsub.to_csv('submission.csv', index=False)\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:46:36.124381Z","iopub.execute_input":"2023-01-02T06:46:36.125141Z","iopub.status.idle":"2023-01-02T06:46:36.144424Z","shell.execute_reply.started":"2023-01-02T06:46:36.125091Z","shell.execute_reply":"2023-01-02T06:46:36.142920Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## データセットの分割方法","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n    \n    print(f'fold_id: {fold_id}')\n    print(f'y_tr y==1 rate: {sum(y_tr)/len(y_tr)}')\n    print(f'y_val y==1 rate: {sum(y_val)/len(y_val)}')","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:51:48.462483Z","iopub.execute_input":"2023-01-02T06:51:48.462924Z","iopub.status.idle":"2023-01-02T06:51:48.482852Z","shell.execute_reply.started":"2023-01-02T06:51:48.462893Z","shell.execute_reply":"2023-01-02T06:51:48.481787Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"fold_id: 0\ny_tr y==1 rate: 0.38342696629213485\ny_val y==1 rate: 0.3854748603351955\nfold_id: 1\ny_tr y==1 rate: 0.3856942496493689\ny_val y==1 rate: 0.37640449438202245\nfold_id: 2\ny_tr y==1 rate: 0.39831697054698456\ny_val y==1 rate: 0.3258426966292135\nfold_id: 3\ny_tr y==1 rate: 0.3856942496493689\ny_val y==1 rate: 0.37640449438202245\nfold_id: 4\ny_tr y==1 rate: 0.36605890603085556\ny_val y==1 rate: 0.4550561797752809\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### y==1の割合を維持して分割する","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n    \n    print(f'fold_id: {fold_id}')\n    print(f'y_tr y==1 rate: {sum(y_tr)/len(y_tr)}')\n    print(f'y_val y==1 rate: {sum(y_val)/len(y_val)}')","metadata":{"execution":{"iopub.status.busy":"2023-01-02T06:55:53.000749Z","iopub.execute_input":"2023-01-02T06:55:53.001247Z","iopub.status.idle":"2023-01-02T06:55:53.025980Z","shell.execute_reply.started":"2023-01-02T06:55:53.001205Z","shell.execute_reply":"2023-01-02T06:55:53.024660Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"fold_id: 0\ny_tr y==1 rate: 0.38342696629213485\ny_val y==1 rate: 0.3854748603351955\nfold_id: 1\ny_tr y==1 rate: 0.38429172510518933\ny_val y==1 rate: 0.38202247191011235\nfold_id: 2\ny_tr y==1 rate: 0.38429172510518933\ny_val y==1 rate: 0.38202247191011235\nfold_id: 3\ny_tr y==1 rate: 0.38429172510518933\ny_val y==1 rate: 0.38202247191011235\nfold_id: 4\ny_tr y==1 rate: 0.38288920056100983\ny_val y==1 rate: 0.38764044943820225\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ny_preds = []\nmodels= []\noof_train = np.zeros((len(X_train), ))\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n\ncategorical_features = ['Embarked', 'Pclass', 'Sex']\n\nparams = {\n    'objective':'binary',\n    'max_bin':300,\n    'learning_rate':0.05,\n    'num_leaves':40\n}\n\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n    \n    lgb_train = lgb.Dataset(X_tr, y_tr,\n                           categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_val, y_val,\n                          reference=lgb_train,\n                          categorical_feature=categorical_features)\n    \n    model = lgb.train(params, lgb_train,\n                     valid_sets=[lgb_train, lgb_eval],\n                     verbose_eval=10,\n                     num_boost_round=1000,\n                     early_stopping_rounds=10)\n    \n    oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    \n    y_preds.append(y_pred)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T07:15:05.030265Z","iopub.execute_input":"2023-01-02T07:15:05.030845Z","iopub.status.idle":"2023-01-02T07:15:05.464115Z","shell.execute_reply.started":"2023-01-02T07:15:05.030805Z","shell.execute_reply":"2023-01-02T07:15:05.462935Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n  _log_warning('Using categorical_feature in Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 273, number of negative: 439\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 213\n[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n[LightGBM] [Info] Start training from score -0.475028\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.503721\tvalid_1's binary_logloss: 0.507892\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.426394\tvalid_1's binary_logloss: 0.439962\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.37914\tvalid_1's binary_logloss: 0.401837\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.34819\tvalid_1's binary_logloss: 0.389454\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.325355\tvalid_1's binary_logloss: 0.384696\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.304134\tvalid_1's binary_logloss: 0.381407\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\ttraining's binary_logloss: 0.286799\tvalid_1's binary_logloss: 0.380094\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\ttraining's binary_logloss: 0.270451\tvalid_1's binary_logloss: 0.38769\nEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.286799\tvalid_1's binary_logloss: 0.380094\n[LightGBM] [Info] Number of positive: 274, number of negative: 439\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 214\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n[LightGBM] [Info] Start training from score -0.471371\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.504714\tvalid_1's binary_logloss: 0.51492\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.426855\tvalid_1's binary_logloss: 0.446865\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.377706\tvalid_1's binary_logloss: 0.405187\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.345694\tvalid_1's binary_logloss: 0.389171\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.321568\tvalid_1's binary_logloss: 0.379856\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.300442\tvalid_1's binary_logloss: 0.380428\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[56]\ttraining's binary_logloss: 0.309412\tvalid_1's binary_logloss: 0.379246\n[LightGBM] [Info] Number of positive: 274, number of negative: 439\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 210\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n[LightGBM] [Info] Start training from score -0.471371\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.503367\tvalid_1's binary_logloss: 0.535264\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.426364\tvalid_1's binary_logloss: 0.475862\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.375461\tvalid_1's binary_logloss: 0.435118\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.343273\tvalid_1's binary_logloss: 0.41869\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.318722\tvalid_1's binary_logloss: 0.409675\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\ttraining's binary_logloss: 0.297665\tvalid_1's binary_logloss: 0.406383\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\ttraining's binary_logloss: 0.28057\tvalid_1's binary_logloss: 0.406807\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[66]\ttraining's binary_logloss: 0.287052\tvalid_1's binary_logloss: 0.405084\n[LightGBM] [Info] Number of positive: 274, number of negative: 439\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 217\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n[LightGBM] [Info] Start training from score -0.471371\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.501601\tvalid_1's binary_logloss: 0.536829\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.418206\tvalid_1's binary_logloss: 0.477298\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.368991\tvalid_1's binary_logloss: 0.448192\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.337823\tvalid_1's binary_logloss: 0.446489\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.355218\tvalid_1's binary_logloss: 0.44507\n[LightGBM] [Info] Number of positive: 273, number of negative: 440\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 218\n[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 9\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n[LightGBM] [Info] Start training from score -0.477303\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 10 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttraining's binary_logloss: 0.490414\tvalid_1's binary_logloss: 0.554395\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttraining's binary_logloss: 0.410196\tvalid_1's binary_logloss: 0.511756\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttraining's binary_logloss: 0.360281\tvalid_1's binary_logloss: 0.492094\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttraining's binary_logloss: 0.325812\tvalid_1's binary_logloss: 0.483975\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttraining's binary_logloss: 0.302751\tvalid_1's binary_logloss: 0.487259\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[44]\ttraining's binary_logloss: 0.315681\tvalid_1's binary_logloss: 0.482556\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(oof_train).to_csv('oof_train_skfold.csv', index=False)\nprint(oof_train[:10])\n\nscores = [\n    m.best_score['valid_1']['binary_logloss'] for m in models\n]\nscore = sum(scores) / len(scores)\nprint('===CV scores===')\nprint(scores)\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2023-01-02T07:15:16.993216Z","iopub.execute_input":"2023-01-02T07:15:16.993710Z","iopub.status.idle":"2023-01-02T07:15:17.009597Z","shell.execute_reply.started":"2023-01-02T07:15:16.993672Z","shell.execute_reply":"2023-01-02T07:15:17.008608Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[0.10743915 0.9336148  0.24343427 0.97174844 0.23722008 0.05967737\n 0.10523416 0.27028808 0.37330822 0.9413475 ]\n===CV scores===\n[0.38009408187107163, 0.37924619589793584, 0.4050842067940025, 0.4450699329180633, 0.48255560255294955]\n0.41841000400680456\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred_oof = (oof_train > 0.5).astype(int)\ny_sub[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-02T07:16:43.016178Z","iopub.execute_input":"2023-01-02T07:16:43.016721Z","iopub.status.idle":"2023-01-02T07:16:43.026290Z","shell.execute_reply.started":"2023-01-02T07:16:43.016676Z","shell.execute_reply":"2023-01-02T07:16:43.025192Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"},"metadata":{}}]},{"cell_type":"code","source":"sub['Survived'] = y_sub\nsub.to_csv('submission_lightgbm_skfold.csv', index=False)\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T07:30:42.274640Z","iopub.execute_input":"2023-01-02T07:30:42.275116Z","iopub.status.idle":"2023-01-02T07:30:42.293122Z","shell.execute_reply.started":"2023-01-02T07:30:42.275054Z","shell.execute_reply":"2023-01-02T07:30:42.291810Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}